---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python [conda env:.conda-scirpy_runtime_benchmark]
    language: python
    name: conda-env-.conda-scirpy_runtime_benchmark-py
---

```python
%load_ext autoreload
%autoreload 2
import sys
import scirpy as ir
import scanpy as sc
import random
import pandas as pd
import numpy as np
import warnings
import scipy

warnings.filterwarnings("ignore", category=FutureWarning)
import matplotlib.pyplot as plt
from multiprocessing import Pool
import powerlaw
import functools
from random import random
from tqdm import tqdm
```

# Load and prepare data

 * Real-world single-cell TCR data (100k cells)

```python
adata = ir.datasets.wu2020()
```

```python
adata = adata[adata.obs["has_tcr"] == "True", :]
```

#### Call clonotypes based on sequence identity

```python
ir.pp.tcr_neighbors(
    adata,
    metric="identity",
    receptor_arms="all",
    dual_tcr="primary_only",
    cutoff=0,
    sequence="nt",
)
```

```python
ir.tl.define_clonotypes(adata)
```

* Simulated TCR data (using immuneSIM): 
   - 500k clonotypes
   - some of the sequences are duplicated, resulting in ~460k unique CDR3 nucleotide sequences

```python
tra_seqs = (
    pd.read_csv("../results/01_simulate/cdr3_a.tsv", sep="\t")
    .drop_duplicates("junction")
    .reset_index(drop=True)
)
trb_seqs = (
    pd.read_csv("../results/01_simulate/cdr3_b.tsv", sep="\t")
    .drop_duplicates("junction")
    .reset_index(drop=True)
)
```

```python
tra_seqs.shape, trb_seqs.shape
```

# Simulate adata objects

```python
clonotype_sizes = np.array(sorted(adata.obs.groupby("clonotype").size(), reverse=True))
```

 * The clonotype size distribution follows a power law as we can appreciate on the log-log plot. 
 * However, the power law distribution generated by ImmuneSIM clearly has different characteristics than 
   the one behind the single-cell data



```python
plt.loglog(
    range(len(tra_seqs["counts"])),
    tra_seqs["counts"],
    ".",
    label="500k simulated clonotypes",
)
plt.loglog(
    np.arange(0, len(clonotype_sizes)), clonotype_sizes, ".", label="100k single cells"
)
plt.legend()
```

 * Therefore, we use the [powerlaw](https://github.com/jeffalstott/powerlaw) package
   to fit the distributions of the single-cell data. 

```python
# skip the first 50, these don't seem to behave power-law like
results = powerlaw.Fit(clonotype_sizes)
print(results.power_law.alpha)
print(results.power_law.xmin)
```

 * We use the inverse CDF of the powerlaw distribution, to randomly sample from the fitted distribution
     - see also https://stats.stackexchange.com/a/406705/101273

```python
def inv_cdf(x_min, alpha, r):
    """r is a random number between 0 and 1"""
    return x_min * (1 - r) ** (-1 / (alpha - 1))
```

```python
def sample_clonotypes(clonotypes, n_cells):
    """Sample clonotypes from a list of clonotypes until a certain number of cells is reached. """
    clonotypes = clonotypes.copy()
    np.random.shuffle(clonotypes)
    sampled_cells = 0
    i = 0
    while sampled_cells < n_cells:
        s = clonotypes[i]
        sampled_cells += s
        i += 1
        yield s
```

```python
def get_clonotype_sizes(n_cells, inv_cdf_fit):
    r = np.random.rand(np.minimum(tra_seqs.shape[0], trb_seqs.shape[0]))
    x_smp = np.round(inv_cdf_fit(r))
    return np.array(sorted(sample_clonotypes(x_smp, n_cells), reverse=True))
```

```python
np.random.seed(123)
x_min = 1
r = results.power_law.alpha
inv_cdf_fit = functools.partial(inv_cdf, x_min, r)

x_smp = get_clonotype_sizes(96100, inv_cdf_fit)
x_smp_10 = get_clonotype_sizes(1000000, inv_cdf_fit)
```

* We can now see that the simulated distribution of clonotype sizes is highly similar. 
* The sizes of the largest clonotypes seems to be over-estimated by the simulation. 
    - This is ok, as it will just result in a more conservative benchmark (the performance is limited in the number of edges in the cell-cell interaction graph. Large clonotypes contribute a majority of these edges)

```python
plt.loglog(
    np.arange(0, len(clonotype_sizes)),
    clonotype_sizes,
    ".",
    color="orange",
    label=f"original ({np.sum(clonotype_sizes)} cells)",
)
plt.loglog(
    np.arange(0, len(x_smp)),
    x_smp,
    ".",
    color="green",
    label=f"simulated ({np.sum(x_smp)} cells)",
)
plt.loglog(
    np.arange(0, len(x_smp_10)),
    x_smp_10,
    ".",
    color="blue",
    label=f"simulated ({np.sum(x_smp_10)} cells)",
)
plt.ylabel("clonotype size")
plt.xlabel("clonotype rank")
plt.legend()
```

 * Generate simulated adata with different sizes

```python
def make_adata(n_cells):
    records = []
    clonotype_sizes = get_clonotype_sizes(n_cells, inv_cdf_fit)
    for i, freq in enumerate(clonotype_sizes):
        for _ in range(int(freq)):
            records.append(
                {
                    "TRA_1_cdr3": tra_seqs["junction_aa"][i],
                    "TRA_1_cdr3_nt": tra_seqs["junction"][i],
                    "TRB_1_cdr3": trb_seqs["junction_aa"][i],
                    "TRB_1_cdr3_nt": trb_seqs["junction"][i],
                    "has_tcr": "True",
                }
            )
    tmp_adata = sc.AnnData(
        X=np.empty((len(records), 0)), obs=pd.DataFrame.from_records(records)
    )
    tmp_adata.write_h5ad(
        "../results/03_simulate_adata/adata_{}.h5ad".format(n_cells), compression="lzf"
    )
```

```python
sizes = [
    10000,
    50000,
    100000,
    200000,
    300000,
    400000,
    500000,
    600000,
    700000,
    800000,
    900000,
    1000000,
]
with Pool(len(sizes)) as p:
    p.map(make_adata, sizes)
```

```python

```
